{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO\n",
    "\n",
    "    Procent odpowiedzi poprawnych (accuracy) w zależności od parametru lambda.\n",
    "    Liczba różnych odpowiedzi (tzn. odp_uni != odp_bigram) w zależności od parametru lambda.\n",
    "    Tabele poprawności według kategorii dla każdej z wartości parametru lambda.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. Procent poprawnych (accuracy, czyli skuteczność) w zależności od parametru lambda. DONE\n",
    "\n",
    "2. Liczba różnych odpowiedzi (tzn. odp_uni != odp_bigram) w zależności od parametru lambda. DONE\n",
    "\n",
    "3. Skuteczność z podziałem na: type, category, basic_type_operation w zależności od parametru lambda. Done\n",
    "\n",
    "4. Funkcja generująca tabele ze skutecznością powinna:\n",
    "    a. sprawdzić czy `None` występują zawsze parami tzn. w modelu uni- i bigramowym - inaczej error DONE\n",
    "    \n",
    "    b. wyniki wspólne dla wszystkich zapisywać do oddzielnej ramki danych, tzn. % None, skutecznośc uni, ogólna (bez podziału) skuteczność bi\n",
    "    c. funkcja nie może sortować ramek pośrednich po accuracy, bo wtedy się nie połączą w jedną dużą DONE\n",
    "    \n",
    "    d. dla każdej lambdy tworzony jest słownik filtrowanych ramek danych DONE\n",
    "    \n",
    "    e. oddzielna ramka danych ze zliczeniem: wg type, wg category, wg basic_operation_type, wg type+basic_op, wg category+basic_op, wg type+cat i wg wszystkich trzech DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predykcji zmiennej celu, czyli poprawnego zapisu błędu, dokonano przy użyciu następujących wartości parametru `lambda`. Parametr ten jest istotny jedynie z punktu widzenia modelu dwugramowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_set_with_answers_no_lang_error_scaling_0.20_lambda.csv\n",
      "test_set_with_answers_no_lang_error_scaling_0.33_lambda.csv\n",
      "test_set_with_answers_no_lang_error_scaling_0.5_lambda.csv\n",
      "test_set_with_answers_no_lang_error_scaling_0.66_lambda.csv\n",
      "test_set_with_answers_no_lang_error_scaling_0.75_lambda.csv\n",
      "test_set_with_answers_no_lang_error_scaling_0.90_lambda.csv\n",
      "test_set_with_answers_no_lang_error_scaling_0.95_lambda.csv\n",
      "test_set_with_answers_no_lang_error_scaling_1.0_lambda.csv\n"
     ]
    }
   ],
   "source": [
    "! ls ../results/ | grep test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W plikach z predykcjami znajdują się także predykcje dla modelu 1-gramowego. Są zawsze takie same, ponieważ model 1-gramowy nie zależy od parametru `lambda`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy w kolumnach `unigram_case` i/lub `bigram_case` znajduje się `NaN` oznacza to, że model kanału z błędem zwrócił dla analizowanej operacji `None`. `None` wiążę się z: \n",
    " 1. brakiem kandydatów (wygenerowane przez algorytm DL słowa nie znajdują się na liście istniejących słów języka polskiego) \n",
    " 2. błędem w zbiorze testowym określono ciąg jedynie zakazanych znaków (tzn. innych niż litery alfabetu łacińskiego rozszerzonego o polskie znaki diakrytyczne) - po przeprowadzeniu czyszczenia powstaje pusty napis, z którego nie można generować sensownych nowych słów\n",
    " 3. wskazany błąd nie znajduje się w zdaniu\n",
    " \n",
    "Przypadki 2 oraz 3 są rzadkie - stanowią nie więcej niż 30 obserwacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(file):\n",
    "    return pd.read_csv('../results/{}'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lambda_from_df(file):\n",
    "    return re.search('\\d\\\\.\\d+', file).group().replace('.', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nones(dataframe):\n",
    "    \"\"\"\n",
    "    Return number of Nones. If number of Nones is not equal among uni- and bigram model raise an error.\n",
    "    \"\"\"\n",
    "    df_unigram_nan = dataframe.loc[dataframe['unigram_case'].isna()]\n",
    "    df_bigram_nan = dataframe.loc[dataframe['bigram_case'].isna()]\n",
    "    \n",
    "    diff_uni_bi = set(df_unigram_nan.index) - set(df_bigram_nan.index)\n",
    "    diff_bi_uni = set(df_bigram_nan.index) - set(df_unigram_nan.index)\n",
    "    # empty set casts to False\n",
    "    if not diff_uni_bi and not diff_bi_uni:\n",
    "        return df_unigram_nan.shape[0] / dataframe.shape[0]\n",
    "    else:\n",
    "        print('Different number of Nones in uni- and bigram model.') \n",
    "        print(\"Uni - bi: \", len(diff_uni_bi))\n",
    "        print(\"Bi - uni: \", len(diff_bi_uni)) \n",
    "        return df_bigram_nan.shape[0] / dataframe.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes_with_answers(dataframe):\n",
    "    return dataframe.dropna(subset=['unigram_case', 'bigram_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_correctness_column(dataframe):\n",
    "    \"\"\"\n",
    "    Accepts a dataframe that hasn't got any Nones as answers\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe['is_correct_uni'] = dataframe.apply(lambda x: int(x['gold_standard'] == x['unigram_case']), axis=1)\n",
    "    dataframe['is_correct_bi'] = dataframe.apply(lambda x: int(x['gold_standard'] == x['bigram_case']), axis=1)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(dataframe):\n",
    "    \"\"\"\n",
    "    Accept a dataframe that hasn't got any Nones as answers and has 0/1 columns informing of answers correctness\n",
    "    \"\"\"\n",
    "    \n",
    "    stats_dict = dict()\n",
    "    \n",
    "    uni_bi_diff_no = dataframe.loc[dataframe['unigram_case'] != dataframe['bigram_case']].shape[0]\n",
    "    uni_better_bi_no = dataframe.loc[(dataframe['is_correct_uni'] == 1) & (dataframe['is_correct_bi'] == 0)].shape[0]\n",
    "    bi_better_uni_no = dataframe.loc[(dataframe['is_correct_uni'] == 0) & (dataframe['is_correct_bi'] == 1)].shape[0]\n",
    "    \n",
    "    df_correct_uni = dataframe.loc[dataframe['gold_standard'] == dataframe['unigram_case']]\n",
    "    df_correct_bi = dataframe.loc[dataframe['gold_standard'] == dataframe['bigram_case']]\n",
    "    \n",
    "    general_accuracy_uni = df_correct_uni.shape[0] / dataframe.shape[0]\n",
    "    general_accuracy_bi = df_correct_bi.shape[0] / dataframe.shape[0]\n",
    "    \n",
    "    dataframe_full = attach_correctness_column(dataframe)\n",
    "    \n",
    "    accuracy_by_type_uni = dataframe_full.groupby(['type']).agg({'is_correct_uni': ['mean']})\n",
    "    accuracy_by_category_uni = dataframe_full.groupby(['category']).agg({'is_correct_uni': ['mean']})\n",
    "    accuracy_by_operation_uni = dataframe_full.groupby(['basic_type_operation']).agg({'is_correct_uni': ['mean']})\n",
    "    accuracy_by_all_uni = dataframe_full.groupby(['type', 'category', 'basic_type_operation']).agg({'is_correct_uni': ['mean']})\n",
    "    \n",
    "    accuracy_by_type_bi = dataframe_full.groupby(['type']).agg({'is_correct_bi': ['mean']})\n",
    "    accuracy_by_category_bi = dataframe_full.groupby(['category']).agg({'is_correct_bi': ['mean']})\n",
    "    accuracy_by_operation_bi = dataframe_full.groupby(['basic_type_operation']).agg({'is_correct_bi': ['mean']})\n",
    "    accuracy_by_all_bi = dataframe_full.groupby(['type', 'category', 'basic_type_operation']).agg({'is_correct_bi': ['mean']})\n",
    "    \n",
    "    stats_dict['accuracy_by_type_uni'] = accuracy_by_type_uni\n",
    "    stats_dict['accuracy_by_category_uni'] = accuracy_by_category_uni\n",
    "    stats_dict['accuracy_by_operation_uni'] = accuracy_by_operation_uni\n",
    "    stats_dict['accuracy_by_all_uni'] = accuracy_by_all_uni\n",
    "    \n",
    "    stats_dict['accuracy_by_type_bi'] = accuracy_by_type_bi\n",
    "    stats_dict['accuracy_by_category_bi'] = accuracy_by_category_bi\n",
    "    stats_dict['accuracy_by_operation_bi'] = accuracy_by_operation_bi\n",
    "    stats_dict['accuracy_by_all_bi'] = accuracy_by_all_bi\n",
    "    \n",
    "    stats_dict['general_accuracy_uni'] = general_accuracy_uni\n",
    "    stats_dict['general_accuracy_bi'] = general_accuracy_bi\n",
    "    \n",
    "    stats_dict['uni_bi_diff_no'] = uni_bi_diff_no\n",
    "    stats_dict['uni_better_bi_no'] = uni_better_bi_no\n",
    "    stats_dict['bi_better_uni_no'] = bi_better_uni_no\n",
    "    \n",
    "    return stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_dataframes(accuracy_by_all, df_answers):\n",
    "    \"\"\"\n",
    "    Accept a dataframe that contains summary of accuracy for each type, category and operation.\n",
    "    Based on the aforementioned df filter the dataframe with answers.\n",
    "    Return a dictionary of filtered dataframes.\n",
    "    \"\"\"\n",
    "    \n",
    "    dfs_dict = dict()\n",
    "    \n",
    "    for i in range(accuracy_by_all.shape[0]):\n",
    "    \n",
    "        # key indicates type, category and basic_type_operation\n",
    "        col_tuple = accuracy_by_all.iloc[i].name\n",
    "        key = re.sub(\"/| \", \"_\", \" \".join(col_tuple))\n",
    "\n",
    "        # value is a dataframe filtered with key elements\n",
    "        mask = (df_answers['type'] == col_tuple[0]) & (df_answers['category'] == col_tuple[1]) & (df_answers['basic_type_operation'] == col_tuple[2])\n",
    "\n",
    "        # get percentage of correct answers for each category\n",
    "        percentage = accuracy_by_all.iloc[i].values[0]\n",
    "\n",
    "        dfs_dict[key] = (df_answers[mask], percentage)\n",
    "    \n",
    "    return dfs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_of_observations(dataframe):\n",
    "    \"\"\"\n",
    "    Accepts a dataframe that hasn't got any Nones as answers.\n",
    "    \"\"\"\n",
    "    \n",
    "    count_by_type = dataframe.groupby(['type']).agg(['count'])['text_with_error'].sort_values(by='count', ascending=False)\n",
    "    count_by_category = dataframe.groupby(['category']).agg(['count'])['text_with_error'].sort_values(by='count', ascending=False)\n",
    "    count_by_operation = dataframe.groupby(['basic_type_operation']).agg(['count'])['text_with_error'].sort_values(by='count', ascending=False)\n",
    "    \n",
    "    count_by_type_category = dataframe.groupby(['type', 'category']).agg(['count'])['text_with_error'].sort_values(by='count', ascending=False)\n",
    "    count_by_type_operation = dataframe.groupby(['type', 'basic_type_operation']).agg(['count'])['text_with_error'].sort_values(by='count', ascending=False)\n",
    "    count_by_all = dataframe.groupby(['type', 'category', 'basic_type_operation']).agg(['count'])['text_with_error'].sort_values(by='count', ascending=False)\n",
    "    \n",
    "    with pd.ExcelWriter('../results/count_info/count_excel.xlsx') as writer:\n",
    "        count_by_type.to_excel(writer, sheet_name='type')\n",
    "        count_by_category.to_excel(writer, sheet_name='category')\n",
    "        count_by_operation.to_excel(writer, sheet_name='operation')\n",
    "        count_by_type_category.to_excel(writer, sheet_name='type_category')\n",
    "        count_by_type_operation.to_excel(writer, sheet_name='type_operation')\n",
    "        count_by_all.to_excel(writer, sheet_name='all')\n",
    "    \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_stats():\n",
    "    \n",
    "    # structures for holding data #\n",
    "    # lambda-accuracy \n",
    "    lambda_col = list()\n",
    "    accuracy_col = list()\n",
    "    \n",
    "    # different answers no\n",
    "    diff_no_col = list()\n",
    "    uni_better_bi = list()\n",
    "    bi_better_uni = list()\n",
    "    \n",
    "    # single values\n",
    "    single_values_dict = dict()\n",
    "    \n",
    "    # accuracy by type (index-only dataframes)\n",
    "    \n",
    "    ##############################\n",
    "    \n",
    "    first_pass_complete = False\n",
    "    \n",
    "    for filename in sorted(os.listdir('../results/')):\n",
    "        if filename.endswith('.csv'):\n",
    "            print(\"Analysing \", filename)\n",
    "            print()\n",
    "            # get dataframe with answers (no Nones)\n",
    "            df_raw = load_dataframe(filename)\n",
    "            \n",
    "            try:\n",
    "                lambda_par = get_lambda_from_df(filename)\n",
    "            except:\n",
    "                print(filename)\n",
    "            \n",
    "            # check if Nones correspond to oen another in unigram and bigram\n",
    "            single_values_dict['pct_nones'] = check_nones(df_raw)\n",
    "            \n",
    "            # dataframes that has no Nones\n",
    "            df_answers = get_dataframes_with_answers(df_raw)\n",
    "            \n",
    "            # attach correctness info\n",
    "            df_answers = attach_correctness_column(df_answers)\n",
    "            \n",
    "            # compute stats and keep in a dictionary\n",
    "            stats_dict = get_stats(df_answers)\n",
    "            \n",
    "            if not first_pass_complete:\n",
    "                # used to gather data about unigram model\n",
    "                # and initialise accuracy by type/category/operation dataframes\n",
    "                first_pass_complete = True\n",
    "                \n",
    "                # counts must be computed only once\n",
    "                get_counts_of_observations(df_answers)\n",
    "                \n",
    "                # accuracy of unigram model is constant w.r.t. lambda parameter\n",
    "                single_values_dict['unigram_acc'] = stats_dict['general_accuracy_uni']\n",
    "                \n",
    "                # initialisation\n",
    "                df_acc_type = pd.DataFrame(index=stats_dict['accuracy_by_type_uni'].index)\n",
    "                df_acc_type['unigram'] = stats_dict['accuracy_by_type_uni'][('is_correct_uni', 'mean')]\n",
    "                \n",
    "                df_acc_category = pd.DataFrame(index=stats_dict['accuracy_by_category_uni'].index)\n",
    "                df_acc_category['unigram'] = stats_dict['accuracy_by_category_uni'][('is_correct_uni', 'mean')]\n",
    "                \n",
    "                df_acc_operation = pd.DataFrame(index=stats_dict['accuracy_by_operation_uni'].index)\n",
    "                df_acc_operation['unigram'] = stats_dict['accuracy_by_operation_uni'][('is_correct_uni', 'mean')]\n",
    "                \n",
    "                df_acc_all = pd.DataFrame(index=stats_dict['accuracy_by_all_uni'].index)\n",
    "                df_acc_all['unigram'] = stats_dict['accuracy_by_all_uni'][('is_correct_uni', 'mean')]\n",
    "                \n",
    "                # end of initialisation\n",
    "            \n",
    "            df_acc_type[lambda_par] = stats_dict['accuracy_by_type_bi'][('is_correct_bi', 'mean')]\n",
    "            df_acc_category[lambda_par] = stats_dict['accuracy_by_category_bi'][('is_correct_bi', 'mean')]\n",
    "            df_acc_operation[lambda_par] = stats_dict['accuracy_by_operation_bi'][('is_correct_bi', 'mean')]\n",
    "            df_acc_all[lambda_par] = stats_dict['accuracy_by_all_bi'][('is_correct_bi', 'mean')]\n",
    "            \n",
    "            lambda_col.append(lambda_par)\n",
    "            accuracy_col.append(stats_dict['general_accuracy_bi'])\n",
    "            diff_no_col.append(stats_dict['uni_bi_diff_no'])\n",
    "            uni_better_bi.append(stats_dict['uni_better_bi_no'])\n",
    "            bi_better_uni.append(stats_dict['bi_better_uni_no'])\n",
    "            \n",
    "            # save filtered dataframes (dictionary) to pickle\n",
    "            with open('../results/pickles/lambda_{}_filtered_dfs.p'.format(lambda_par), 'wb') as file:\n",
    "                filtered_dfs = get_filtered_dataframes(df_acc_all, df_answers)\n",
    "                pickle.dump(filtered_dfs, file)\n",
    "    \n",
    "    # save dataframes with accuracy to excel\n",
    "    with pd.ExcelWriter('../results/accuracy_by_stats.xlsx') as writer:\n",
    "        df_acc_type.to_excel(writer, sheet_name='type')\n",
    "        df_acc_category.to_excel(writer, sheet_name='category')\n",
    "        df_acc_operation.to_excel(writer, sheet_name='operation')\n",
    "        df_acc_all.to_excel(writer, sheet_name='all')\n",
    "        \n",
    "    # save lambda-accuracy, lambda-diff_no dataframe to excel\n",
    "    lambda_accuracy_stats = pd.DataFrame(\n",
    "    {\n",
    "        'lambda': lambda_col,\n",
    "        'accuracy': accuracy_col,\n",
    "#         'total_diff': diff_no_col,\n",
    "        'uni_better_bi': uni_better_bi,\n",
    "        'bi_better_uni': bi_better_uni\n",
    "    })\n",
    "    \n",
    "    # save single-files dict to excel\n",
    "    single_values = pd.DataFrame(single_values_dict, index=range(len(single_values_dict.keys())))\n",
    "    \n",
    "    with pd.ExcelWriter('../results/general_stats.xlsx') as writer:\n",
    "        lambda_accuracy_stats.to_excel(writer, sheet_name='by_lambda')\n",
    "        single_values.to_excel(writer, sheet_name='single_values')\n",
    "    \n",
    "    print(\"Done all!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing  test_set_with_answers_no_lang_error_scaling_0.20_lambda.csv\n",
      "\n",
      "Different number of Nones in uni- and bigram model.\n",
      "Uni - bi:  0\n",
      "Bi - uni:  2\n",
      "{'pct_nones': 0.06799417913993823}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawelhdd/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/pawelhdd/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Analysing  test_set_with_answers_no_lang_error_scaling_0.33_lambda.csv\n",
      "\n",
      "Different number of Nones in uni- and bigram model.\n",
      "Uni - bi:  0\n",
      "Bi - uni:  2\n",
      "{'pct_nones': 0.06799417913993823, 'unigram_acc': 0.8679200191189357}\n",
      "Analysing  test_set_with_answers_no_lang_error_scaling_0.5_lambda.csv\n",
      "\n",
      "Different number of Nones in uni- and bigram model.\n",
      "Uni - bi:  0\n",
      "Bi - uni:  2\n",
      "{'pct_nones': 0.06799417913993823, 'unigram_acc': 0.8679200191189357}\n",
      "Analysing  test_set_with_answers_no_lang_error_scaling_0.66_lambda.csv\n",
      "\n",
      "Different number of Nones in uni- and bigram model.\n",
      "Uni - bi:  0\n",
      "Bi - uni:  2\n",
      "{'pct_nones': 0.06799417913993823, 'unigram_acc': 0.8679200191189357}\n",
      "Analysing  test_set_with_answers_no_lang_error_scaling_0.75_lambda.csv\n",
      "\n",
      "Different number of Nones in uni- and bigram model.\n",
      "Uni - bi:  0\n",
      "Bi - uni:  2\n",
      "{'pct_nones': 0.06799417913993823, 'unigram_acc': 0.8679200191189357}\n",
      "Analysing  test_set_with_answers_no_lang_error_scaling_0.90_lambda.csv\n",
      "\n",
      "Different number of Nones in uni- and bigram model.\n",
      "Uni - bi:  0\n",
      "Bi - uni:  2\n",
      "{'pct_nones': 0.06799417913993823, 'unigram_acc': 0.8679200191189357}\n",
      "Analysing  test_set_with_answers_no_lang_error_scaling_0.95_lambda.csv\n",
      "\n",
      "Different number of Nones in uni- and bigram model.\n",
      "Uni - bi:  0\n",
      "Bi - uni:  2\n",
      "{'pct_nones': 0.06799417913993823, 'unigram_acc': 0.8679200191189357}\n",
      "Analysing  test_set_with_answers_no_lang_error_scaling_1.0_lambda.csv\n",
      "\n",
      "Different number of Nones in uni- and bigram model.\n",
      "Uni - bi:  0\n",
      "Bi - uni:  2\n",
      "{'pct_nones': 0.06799417913993823, 'unigram_acc': 0.8679200191189357}\n",
      "Done all!\n"
     ]
    }
   ],
   "source": [
    "wrapper_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
